{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "song_lyrics = pd.read_csv('./data/preprocessed-data/song_lyrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6342 entries, 0 to 6341\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   spotify_id  6342 non-null   object\n",
      " 1   lyrics      6342 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 99.2+ KB\n"
     ]
    }
   ],
   "source": [
    "song_lyrics.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find all types of musical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features pattern for tokenization:\n",
      "['break', 'break \\\\d+', 'breakdown', 'bridge', 'bridge \\\\d+']\n",
      "['chorus', 'chorus \\\\d+', 'coro', 'coro \\\\d+', 'guitar solo']\n",
      "['hook', 'hook \\\\d+', 'instrumental', 'instrumental break', 'instrumental bridge']\n",
      "['instrumental interlude', 'instrumental intro', 'instrumental outro', 'interlude', 'interlude \\\\d+']\n",
      "['intro', 'intro \\\\d+', 'outro', 'outro \\\\d+', 'post-chorus']\n",
      "['post-chorus \\\\d+', 'pre-chorus', 'pre-chorus \\\\d+', 'pre-coro', 'pre-coro \\\\d+']\n",
      "['refrain', 'refrain \\\\d+', 'saxophone solo', 'solo', 'spoken']\n",
      "['verse', 'verse \\\\d+', 'verso', 'verso \\\\d+']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "feature_counts = {}\n",
    "feature_with_number = set()\n",
    "\n",
    "for lyrics in song_lyrics['lyrics']:\n",
    "    # Find all text enclosed in square brackets, capturing feature names with optional numbers\n",
    "    features_found = re.findall(r\"\\[([^\\]:]+)(?: \\d+)?\\]\", lyrics)\n",
    "    unique_features = set()\n",
    "\n",
    "    # Process each found feature\n",
    "    for feature in features_found:\n",
    "        # Ignore the [x2] token completely\n",
    "        if feature.strip().lower() == 'x2' or feature.strip().lower() == '?':\n",
    "            continue\n",
    "\n",
    "        feature_base = re.sub(r\" \\d+\", \"\", feature).strip().lower()  # Remove numbers and standardize\n",
    "        unique_features.add(feature_base)\n",
    "\n",
    "        if re.search(r\" \\d+\", feature):\n",
    "            feature_with_number.add(feature_base)\n",
    "\n",
    "    # Update counts, considering each feature only once per song\n",
    "    for feature in unique_features:\n",
    "        feature_counts[feature] = feature_counts.get(feature, 0) + 1\n",
    "\n",
    "# Filter and add features found more than 10 times to the set for tokenization\n",
    "features_for_tokenization = set()\n",
    "for feature, count in feature_counts.items():\n",
    "    if count > 10:  # Refactor this number to be relative to the dataset if we add more data\n",
    "        features_for_tokenization.add(feature)\n",
    "        if feature in feature_with_number:\n",
    "            features_for_tokenization.add(feature + r\" \\d+\")\n",
    "\n",
    "# Creating the pattern string for tokenization\n",
    "features_pattern = r\"(\" + \"|\".join(features_for_tokenization) + \")\"\n",
    "\n",
    "print(\"Features pattern for tokenization:\")\n",
    "step = 5\n",
    "features_for_tokenization = list(features_for_tokenization)\n",
    "features_for_tokenization.sort()\n",
    "for i in range(0, len(features_for_tokenization), step):\n",
    "    print(features_for_tokenization[i:i+step])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Verse number is not preserved in the tokens\n",
    "# features_pattern = \"(coro|pre-coro|outro|instrumental intro|intro|verso \\d+|hook|post-chorus \\d+|verso|chorus \\d+|verse|interlude \\d+|instrumental outro|pre-coro \\d+|break|bridge|instrumental|instrumental break|outro \\d+|interlude|break \\d+|saxophone solo|instrumental interlude|refrain|bridge \\d+|coro \\d+|intro \\d+|pre-chorus|pre-chorus \\d+|chorus|hook \\d+|verse \\d+|instrumental bridge|spoken|refrain \\d+|guitar solo|post-chorus|breakdown|solo)\"\n",
    "def tokenize_lyrics(lyrics):\n",
    "    # Converting to lowercase\n",
    "    lyrics = lyrics.lower()\n",
    "\n",
    "    # Removing artist names from musical features\n",
    "    lyrics = re.sub(fr\"\\[{features_pattern}:?[^\\]]*?\\]\", r\"[\\1]\", lyrics)\n",
    "\n",
    "    # Splitting the lyrics into lines\n",
    "    lines = lyrics.split('\\n')\n",
    "\n",
    "    # Tokenizing each line\n",
    "    tokens = []\n",
    "    for line in lines:\n",
    "        # Check and skip the [?] token\n",
    "        if '[?]' in line:\n",
    "            line = re.sub(r\"\\[\\?\\]\", \"\", line)  # Ignore the [?] token\n",
    "\n",
    "        # Tokenizing special tokens like [x2] as \"[x2]\"\n",
    "        if '[x2]' in line:\n",
    "            tokens.append(\"[x2]\")\n",
    "            line = re.sub(r\"\\[x2\\]\", \"\", line)  # Remove the special token from the line\n",
    "\n",
    "        # Tokenizing musical features as separate tokens, including those with numbers\n",
    "        musical_features = re.findall(fr\"\\[{features_pattern}(?:\\]|:[^\\]]*\\])\", line)\n",
    "        if musical_features:\n",
    "            for feature in musical_features:\n",
    "                # Capitalize the first letter of each word and add square brackets\n",
    "                capitalized_feature = '[' + ' '.join(word.capitalize() for word in feature.split()) + ']'\n",
    "                tokens.append(capitalized_feature)\n",
    "            line = re.sub(fr\"\\[.*?\\]\", \"\", line).strip()\n",
    "\n",
    "        # Tokenizing words, standalone punctuation, and ellipses as separate tokens\n",
    "        # Added a pattern to capture ellipses before individual periods\n",
    "        line_tokens = re.findall(r\"\\.{3}|[\\w’']+(?:-[a-z’']+)?|[.,!?;]\", line)\n",
    "        tokens.extend(line_tokens)\n",
    "\n",
    "        # Adding a token for line breaks\n",
    "        tokens.append(\"\\n\")\n",
    "\n",
    "    # Removing the last line break token\n",
    "    if tokens and tokens[-1] == \"\\n\":\n",
    "        tokens.pop()\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[Intro]',\n",
      " '\\n',\n",
      " \"'cause\",\n",
      " 'sometimes',\n",
      " 'you',\n",
      " 'just',\n",
      " 'feel',\n",
      " 'tired',\n",
      " '\\n',\n",
      " 'yo',\n",
      " ',',\n",
      " 'left',\n",
      " ',',\n",
      " 'yo',\n",
      " ',',\n",
      " 'left',\n",
      " '\\n',\n",
      " 'feel',\n",
      " 'weak',\n",
      " 'and',\n",
      " 'when',\n",
      " 'you',\n",
      " 'feel',\n",
      " 'weak',\n",
      " '\\n',\n",
      " 'yo',\n",
      " ',',\n",
      " 'left',\n",
      " ',',\n",
      " 'right',\n",
      " ',',\n",
      " 'left',\n",
      " '\\n',\n",
      " 'you',\n",
      " 'feel',\n",
      " 'like',\n",
      " 'you',\n",
      " 'wanna',\n",
      " 'just',\n",
      " 'give',\n",
      " 'up',\n",
      " '\\n',\n",
      " 'yo',\n",
      " ',',\n",
      " 'left',\n",
      " ',',\n",
      " 'yo',\n",
      " ',',\n",
      " 'left',\n",
      " '\\n',\n",
      " 'but',\n",
      " 'you',\n",
      " 'gotta',\n",
      " 'search',\n",
      " 'within',\n",
      " 'you',\n",
      " '\\n',\n",
      " 'yo',\n",
      " ',',\n",
      " 'left',\n",
      " ',',\n",
      " 'right',\n",
      " ',',\n",
      " 'left',\n",
      " '\\n',\n",
      " 'try',\n",
      " 'to',\n",
      " 'find',\n",
      " 'that',\n",
      " 'inner',\n",
      " 'strength',\n",
      " 'and',\n",
      " 'just',\n",
      " 'pull',\n",
      " 'that',\n",
      " 'shit',\n",
      " 'out',\n",
      " 'of',\n",
      " 'you',\n",
      " '\\n',\n",
      " 'yo',\n",
      " ',',\n",
      " 'left',\n",
      " ',',\n",
      " 'yo',\n",
      " ',',\n",
      " 'left',\n",
      " '\\n',\n",
      " 'and',\n",
      " 'get',\n",
      " 'that',\n",
      " 'motivation',\n",
      " 'to',\n",
      " 'not',\n",
      " 'give',\n",
      " 'up',\n",
      " '\\n',\n",
      " 'yo',\n",
      " ',',\n",
      " 'left',\n",
      " ',',\n",
      " 'right',\n",
      " ',',\n",
      " 'left',\n",
      " '\\n',\n",
      " 'and',\n",
      " 'not',\n",
      " 'be',\n",
      " 'a',\n",
      " 'quitter',\n",
      " ',',\n",
      " 'no',\n",
      " 'matter',\n",
      " 'how',\n",
      " 'bad',\n",
      " '\\n',\n",
      " 'yo',\n",
      " ',',\n",
      " 'left',\n",
      " ',',\n",
      " 'yo',\n",
      " ',',\n",
      " 'left',\n",
      " '\\n',\n",
      " 'you',\n",
      " 'wanna',\n",
      " 'just',\n",
      " 'fall',\n",
      " 'flat',\n",
      " 'on',\n",
      " 'your',\n",
      " 'face',\n",
      " 'and',\n",
      " 'collapse',\n",
      " '\\n',\n",
      " 'yo',\n",
      " ',',\n",
      " 'left',\n",
      " ',',\n",
      " 'right',\n",
      " ',',\n",
      " 'left',\n",
      " '\\n',\n",
      " '\\n',\n",
      " '[Verse]',\n",
      " '\\n',\n",
      " \"'til\",\n",
      " 'i',\n",
      " 'collapse',\n",
      " \"i'm\",\n",
      " \"spillin'\",\n",
      " 'these',\n",
      " 'raps',\n",
      " 'long',\n",
      " 'as',\n",
      " 'you',\n",
      " 'feel',\n",
      " \"'em\",\n",
      " '\\n',\n",
      " \"'til\",\n",
      " 'the',\n",
      " 'day',\n",
      " 'that',\n",
      " 'i',\n",
      " 'drop',\n",
      " \"you'll\",\n",
      " 'never',\n",
      " 'say',\n",
      " 'that',\n",
      " \"i'm\",\n",
      " 'not',\n",
      " \"killin'\",\n",
      " \"'em\",\n",
      " '\\n',\n",
      " \"'cause\",\n",
      " 'when',\n",
      " 'i',\n",
      " 'am',\n",
      " 'not',\n",
      " ',',\n",
      " 'then',\n",
      " \"i'ma\",\n",
      " 'stop',\n",
      " \"pennin'\",\n",
      " \"'em\",\n",
      " '\\n',\n",
      " 'and',\n",
      " 'i',\n",
      " 'am',\n",
      " 'not',\n",
      " 'hip-hop',\n",
      " 'and',\n",
      " \"i'm\",\n",
      " 'just',\n",
      " 'not',\n",
      " 'eminem',\n",
      " '\\n',\n",
      " 'subliminal',\n",
      " 'thoughts',\n",
      " ',',\n",
      " 'when',\n",
      " \"i'ma\",\n",
      " 'stop',\n",
      " \"sendin'\",\n",
      " \"'em\",\n",
      " '?',\n",
      " '\\n',\n",
      " 'women',\n",
      " 'are',\n",
      " 'caught',\n",
      " 'in',\n",
      " 'webs',\n",
      " ',',\n",
      " 'spin',\n",
      " \"'em\",\n",
      " 'and',\n",
      " 'hock',\n",
      " 'venom',\n",
      " '\\n',\n",
      " 'adrenaline',\n",
      " 'shots',\n",
      " 'of',\n",
      " 'penicillin',\n",
      " 'could',\n",
      " 'not',\n",
      " 'get',\n",
      " 'the',\n",
      " \"illin'\",\n",
      " 'to',\n",
      " 'stop',\n",
      " '\\n',\n",
      " \"amoxicillin's\",\n",
      " 'just',\n",
      " 'not',\n",
      " 'real',\n",
      " 'enough',\n",
      " '\\n',\n",
      " 'the',\n",
      " 'criminal',\n",
      " ',',\n",
      " \"cop-killin'\",\n",
      " ',',\n",
      " 'hip-hop',\n",
      " 'villain',\n",
      " '\\n',\n",
      " 'a',\n",
      " 'minimal',\n",
      " 'swap',\n",
      " 'to',\n",
      " 'cop',\n",
      " 'millions',\n",
      " 'of',\n",
      " 'pac',\n",
      " 'listeners',\n",
      " '\\n',\n",
      " \"you're\",\n",
      " \"comin'\",\n",
      " 'with',\n",
      " 'me',\n",
      " ',',\n",
      " 'feel',\n",
      " 'it',\n",
      " 'or',\n",
      " 'not',\n",
      " '\\n',\n",
      " \"you're\",\n",
      " 'gonna',\n",
      " 'fear',\n",
      " 'it',\n",
      " 'like',\n",
      " 'i',\n",
      " 'showed',\n",
      " 'ya',\n",
      " 'the',\n",
      " 'spirit',\n",
      " 'of',\n",
      " 'god',\n",
      " 'lives',\n",
      " 'in',\n",
      " 'us',\n",
      " '\\n',\n",
      " 'you',\n",
      " 'hear',\n",
      " 'it',\n",
      " 'a',\n",
      " 'lot',\n",
      " ',',\n",
      " 'lyrics',\n",
      " 'to',\n",
      " 'shock',\n",
      " '\\n',\n",
      " 'is',\n",
      " 'it',\n",
      " 'a',\n",
      " 'miracle',\n",
      " 'or',\n",
      " 'am',\n",
      " 'i',\n",
      " 'just',\n",
      " 'product',\n",
      " 'of',\n",
      " 'pop',\n",
      " \"fizzin'\",\n",
      " 'up',\n",
      " '?',\n",
      " '\\n',\n",
      " \"fa'\",\n",
      " 'shizzle',\n",
      " ',',\n",
      " 'my',\n",
      " 'wizzle',\n",
      " ',',\n",
      " 'this',\n",
      " 'is',\n",
      " 'the',\n",
      " 'plot',\n",
      " ',',\n",
      " 'listen',\n",
      " 'up',\n",
      " '\\n',\n",
      " 'you',\n",
      " 'bizzles',\n",
      " 'forgot',\n",
      " ',',\n",
      " 'slizzle',\n",
      " 'does',\n",
      " 'not',\n",
      " 'give',\n",
      " 'a',\n",
      " 'fuck',\n",
      " '\\n',\n",
      " '\\n',\n",
      " '[Chorus]',\n",
      " '\\n',\n",
      " \"'til\",\n",
      " 'the',\n",
      " 'roof',\n",
      " 'comes',\n",
      " 'off',\n",
      " ',',\n",
      " \"'til\",\n",
      " 'the',\n",
      " 'lights',\n",
      " 'go',\n",
      " 'out',\n",
      " '\\n',\n",
      " \"'til\",\n",
      " 'my',\n",
      " 'legs',\n",
      " 'give',\n",
      " 'out',\n",
      " ',',\n",
      " \"can't\",\n",
      " 'shut',\n",
      " 'my',\n",
      " 'mouth',\n",
      " '\\n',\n",
      " \"'til\",\n",
      " 'the',\n",
      " 'smoke',\n",
      " 'clears',\n",
      " 'out',\n",
      " ',',\n",
      " 'am',\n",
      " 'i',\n",
      " 'high',\n",
      " '?',\n",
      " 'perhaps',\n",
      " '\\n',\n",
      " \"i'ma\",\n",
      " 'rip',\n",
      " 'this',\n",
      " 'shit',\n",
      " \"'til\",\n",
      " 'my',\n",
      " 'bones',\n",
      " 'collapse',\n",
      " '\\n',\n",
      " \"'til\",\n",
      " 'the',\n",
      " 'roof',\n",
      " 'comes',\n",
      " 'off',\n",
      " ',',\n",
      " \"'til\",\n",
      " 'the',\n",
      " 'lights',\n",
      " 'go',\n",
      " 'out',\n",
      " '\\n',\n",
      " 'until',\n",
      " 'the',\n",
      " 'roof',\n",
      " ',',\n",
      " 'until',\n",
      " 'the',\n",
      " 'roof',\n",
      " '\\n',\n",
      " \"'til\",\n",
      " 'my',\n",
      " 'legs',\n",
      " 'give',\n",
      " 'out',\n",
      " ',',\n",
      " \"can't\",\n",
      " 'shut',\n",
      " 'my',\n",
      " 'mouth',\n",
      " '\\n',\n",
      " 'the',\n",
      " 'roof',\n",
      " 'comes',\n",
      " 'off',\n",
      " ',',\n",
      " 'the',\n",
      " 'roof',\n",
      " 'comes',\n",
      " 'off',\n",
      " '\\n',\n",
      " \"'til\",\n",
      " 'the',\n",
      " 'smoke',\n",
      " 'clears',\n",
      " 'out',\n",
      " ',',\n",
      " 'am',\n",
      " 'i',\n",
      " 'high',\n",
      " '?',\n",
      " 'perhaps',\n",
      " '\\n',\n",
      " 'until',\n",
      " 'my',\n",
      " 'legs',\n",
      " ',',\n",
      " 'until',\n",
      " 'my',\n",
      " 'legs',\n",
      " '\\n',\n",
      " \"i'ma\",\n",
      " 'rip',\n",
      " 'this',\n",
      " 'shit',\n",
      " \"'til\",\n",
      " 'my',\n",
      " 'bones',\n",
      " 'collapse',\n",
      " '\\n',\n",
      " 'give',\n",
      " 'out',\n",
      " 'from',\n",
      " 'underneath',\n",
      " 'me',\n",
      " '\\n',\n",
      " '\\n',\n",
      " '[Verse]',\n",
      " '\\n',\n",
      " 'music',\n",
      " 'is',\n",
      " 'like',\n",
      " 'magic',\n",
      " ',',\n",
      " \"there's\",\n",
      " 'a',\n",
      " 'certain',\n",
      " \"feelin'\",\n",
      " 'you',\n",
      " 'get',\n",
      " '\\n',\n",
      " 'when',\n",
      " 'you',\n",
      " 'real',\n",
      " 'and',\n",
      " 'you',\n",
      " 'spit',\n",
      " ',',\n",
      " 'and',\n",
      " 'people',\n",
      " 'are',\n",
      " \"feelin'\",\n",
      " 'your',\n",
      " 'shit',\n",
      " '\\n',\n",
      " 'this',\n",
      " 'is',\n",
      " 'your',\n",
      " 'moment',\n",
      " ',',\n",
      " 'and',\n",
      " 'every',\n",
      " 'single',\n",
      " 'minute',\n",
      " 'you',\n",
      " 'spend',\n",
      " '\\n',\n",
      " 'tryna',\n",
      " 'hold',\n",
      " 'on',\n",
      " 'to',\n",
      " 'it',\n",
      " ',',\n",
      " \"'cause\",\n",
      " 'you',\n",
      " 'may',\n",
      " 'never',\n",
      " 'get',\n",
      " 'it',\n",
      " 'again',\n",
      " '\\n',\n",
      " 'so',\n",
      " 'while',\n",
      " \"you're\",\n",
      " 'in',\n",
      " 'it',\n",
      " ',',\n",
      " 'try',\n",
      " 'to',\n",
      " 'get',\n",
      " 'as',\n",
      " 'much',\n",
      " 'shit',\n",
      " 'as',\n",
      " 'you',\n",
      " 'can',\n",
      " '\\n',\n",
      " 'and',\n",
      " 'when',\n",
      " 'your',\n",
      " 'run',\n",
      " 'is',\n",
      " 'over',\n",
      " ',',\n",
      " 'just',\n",
      " 'admit',\n",
      " 'when',\n",
      " \"it's\",\n",
      " 'at',\n",
      " 'its',\n",
      " 'end',\n",
      " '\\n',\n",
      " \"'cause\",\n",
      " \"i'm\",\n",
      " 'at',\n",
      " 'the',\n",
      " 'end',\n",
      " 'of',\n",
      " 'my',\n",
      " 'wits',\n",
      " 'with',\n",
      " 'half',\n",
      " 'the',\n",
      " 'shit',\n",
      " 'that',\n",
      " 'gets',\n",
      " 'in',\n",
      " '\\n',\n",
      " 'i',\n",
      " 'got',\n",
      " 'a',\n",
      " 'list',\n",
      " ',',\n",
      " \"here's\",\n",
      " 'the',\n",
      " 'order',\n",
      " 'of',\n",
      " 'my',\n",
      " 'list',\n",
      " 'that',\n",
      " \"it's\",\n",
      " 'in',\n",
      " '\\n',\n",
      " 'it',\n",
      " 'goes',\n",
      " 'reggie',\n",
      " ',',\n",
      " 'jay-z',\n",
      " ',',\n",
      " '2pac',\n",
      " 'and',\n",
      " 'biggie',\n",
      " '\\n',\n",
      " 'andré',\n",
      " 'from',\n",
      " 'outkast',\n",
      " ',',\n",
      " 'jada',\n",
      " ',',\n",
      " 'kurupt',\n",
      " ',',\n",
      " 'nas',\n",
      " ',',\n",
      " 'and',\n",
      " 'then',\n",
      " 'me',\n",
      " '\\n',\n",
      " 'but',\n",
      " 'in',\n",
      " 'this',\n",
      " 'industry',\n",
      " \"i'm\",\n",
      " 'the',\n",
      " 'cause',\n",
      " 'of',\n",
      " 'a',\n",
      " 'lot',\n",
      " 'of',\n",
      " 'envy',\n",
      " '\\n',\n",
      " 'so',\n",
      " 'when',\n",
      " \"i'm\",\n",
      " 'not',\n",
      " 'put',\n",
      " 'on',\n",
      " 'this',\n",
      " 'list',\n",
      " ',',\n",
      " 'the',\n",
      " 'shit',\n",
      " 'does',\n",
      " 'not',\n",
      " 'offend',\n",
      " 'me',\n",
      " '\\n',\n",
      " \"that's\",\n",
      " 'why',\n",
      " 'you',\n",
      " 'see',\n",
      " 'me',\n",
      " 'walk',\n",
      " 'around',\n",
      " 'like',\n",
      " \"nothing's\",\n",
      " \"botherin'\",\n",
      " 'me',\n",
      " '\\n',\n",
      " 'even',\n",
      " 'though',\n",
      " 'half',\n",
      " 'you',\n",
      " 'people',\n",
      " 'got',\n",
      " 'a',\n",
      " \"fuckin'\",\n",
      " 'problem',\n",
      " 'with',\n",
      " 'me',\n",
      " '\\n',\n",
      " 'you',\n",
      " 'hate',\n",
      " 'it',\n",
      " ',',\n",
      " 'but',\n",
      " 'you',\n",
      " 'know',\n",
      " 'respect',\n",
      " 'you',\n",
      " 'got',\n",
      " 'to',\n",
      " 'give',\n",
      " 'me',\n",
      " '\\n',\n",
      " 'the',\n",
      " \"press's\",\n",
      " 'wet',\n",
      " 'dream',\n",
      " ',',\n",
      " 'like',\n",
      " 'bobby',\n",
      " 'and',\n",
      " 'whitney',\n",
      " 'nate',\n",
      " ',',\n",
      " 'hit',\n",
      " 'me',\n",
      " '!',\n",
      " '\\n',\n",
      " '\\n',\n",
      " '[Chorus]',\n",
      " '\\n',\n",
      " \"'til\",\n",
      " 'the',\n",
      " 'roof',\n",
      " 'comes',\n",
      " 'off',\n",
      " ',',\n",
      " \"'til\",\n",
      " 'the',\n",
      " 'lights',\n",
      " 'go',\n",
      " 'out',\n",
      " '\\n',\n",
      " \"'til\",\n",
      " 'my',\n",
      " 'legs',\n",
      " 'give',\n",
      " 'out',\n",
      " ',',\n",
      " \"can't\",\n",
      " 'shut',\n",
      " 'my',\n",
      " 'mouth',\n",
      " '\\n',\n",
      " \"'til\",\n",
      " 'the',\n",
      " 'smoke',\n",
      " 'clears',\n",
      " 'out',\n",
      " ',',\n",
      " 'am',\n",
      " 'i',\n",
      " 'high',\n",
      " '?',\n",
      " 'perhaps',\n",
      " '\\n',\n",
      " \"i'ma\",\n",
      " 'rip',\n",
      " 'this',\n",
      " 'shit',\n",
      " \"'til\",\n",
      " 'my',\n",
      " 'bones',\n",
      " 'collapse',\n",
      " '\\n',\n",
      " \"'til\",\n",
      " 'the',\n",
      " 'roof',\n",
      " 'comes',\n",
      " 'off',\n",
      " ',',\n",
      " \"'til\",\n",
      " 'the',\n",
      " 'lights',\n",
      " 'go',\n",
      " 'out',\n",
      " '\\n',\n",
      " 'until',\n",
      " 'the',\n",
      " 'roof',\n",
      " ',',\n",
      " 'until',\n",
      " 'the',\n",
      " 'roof',\n",
      " '\\n',\n",
      " \"'til\",\n",
      " 'my',\n",
      " 'legs',\n",
      " 'give',\n",
      " 'out',\n",
      " ',',\n",
      " \"can't\",\n",
      " 'shut',\n",
      " 'my',\n",
      " 'mouth',\n",
      " '\\n',\n",
      " 'the',\n",
      " 'roof',\n",
      " 'comes',\n",
      " 'off',\n",
      " ',',\n",
      " 'the',\n",
      " 'roof',\n",
      " 'comes',\n",
      " 'off',\n",
      " '\\n',\n",
      " \"'til\",\n",
      " 'the',\n",
      " 'smoke',\n",
      " 'clears',\n",
      " 'out',\n",
      " ',',\n",
      " 'am',\n",
      " 'i',\n",
      " 'high',\n",
      " '?',\n",
      " 'perhaps',\n",
      " '\\n',\n",
      " 'until',\n",
      " 'my',\n",
      " 'legs',\n",
      " ',',\n",
      " 'until',\n",
      " 'my',\n",
      " 'legs',\n",
      " '\\n',\n",
      " \"i'ma\",\n",
      " 'rip',\n",
      " 'this',\n",
      " 'shit',\n",
      " \"'til\",\n",
      " 'my',\n",
      " 'bones',\n",
      " 'collapse',\n",
      " '\\n',\n",
      " 'give',\n",
      " 'out',\n",
      " 'from',\n",
      " 'underneath',\n",
      " 'me',\n",
      " '\\n',\n",
      " '\\n',\n",
      " '[Verse]',\n",
      " '\\n',\n",
      " 'soon',\n",
      " 'as',\n",
      " 'a',\n",
      " 'verse',\n",
      " 'starts',\n",
      " ',',\n",
      " 'i',\n",
      " 'eat',\n",
      " 'at',\n",
      " 'an',\n",
      " \"mc's\",\n",
      " 'heart',\n",
      " '\\n',\n",
      " 'what',\n",
      " 'is',\n",
      " 'he',\n",
      " 'thinking',\n",
      " '?',\n",
      " 'how',\n",
      " 'not',\n",
      " 'to',\n",
      " 'go',\n",
      " 'against',\n",
      " 'me',\n",
      " ',',\n",
      " 'smart',\n",
      " '\\n',\n",
      " 'and',\n",
      " \"it's\",\n",
      " 'absurd',\n",
      " 'how',\n",
      " 'people',\n",
      " 'hang',\n",
      " 'on',\n",
      " 'every',\n",
      " 'word',\n",
      " '\\n',\n",
      " \"i'll\",\n",
      " \"prob'ly\",\n",
      " 'never',\n",
      " 'get',\n",
      " 'the',\n",
      " 'props',\n",
      " 'i',\n",
      " 'feel',\n",
      " 'i',\n",
      " 'ever',\n",
      " 'deserve',\n",
      " '\\n',\n",
      " 'but',\n",
      " \"i'll\",\n",
      " 'never',\n",
      " 'be',\n",
      " 'served',\n",
      " ',',\n",
      " 'my',\n",
      " 'spot',\n",
      " 'is',\n",
      " 'forever',\n",
      " 'reserved',\n",
      " '\\n',\n",
      " 'if',\n",
      " 'i',\n",
      " 'ever',\n",
      " 'leave',\n",
      " 'earth',\n",
      " ',',\n",
      " 'that',\n",
      " 'would',\n",
      " 'be',\n",
      " 'the',\n",
      " 'death',\n",
      " 'of',\n",
      " 'me',\n",
      " 'first',\n",
      " '\\n',\n",
      " \"'cause\",\n",
      " 'in',\n",
      " 'my',\n",
      " 'heart',\n",
      " 'of',\n",
      " 'hearts',\n",
      " 'i',\n",
      " 'know',\n",
      " \"nothin'\",\n",
      " 'could',\n",
      " 'ever',\n",
      " 'be',\n",
      " 'worse',\n",
      " '\\n',\n",
      " \"that's\",\n",
      " 'why',\n",
      " \"i'm\",\n",
      " 'clever',\n",
      " 'when',\n",
      " 'i',\n",
      " 'put',\n",
      " 'together',\n",
      " 'every',\n",
      " 'verse',\n",
      " '\\n',\n",
      " 'my',\n",
      " 'thoughts',\n",
      " 'are',\n",
      " 'sporadic',\n",
      " ',',\n",
      " 'i',\n",
      " 'act',\n",
      " 'like',\n",
      " \"i'm\",\n",
      " 'an',\n",
      " 'addict',\n",
      " '\\n',\n",
      " 'i',\n",
      " 'rap',\n",
      " 'like',\n",
      " \"i'm\",\n",
      " 'addicted',\n",
      " 'to',\n",
      " 'smack',\n",
      " 'like',\n",
      " \"i'm\",\n",
      " 'kim',\n",
      " 'mathers',\n",
      " '\\n',\n",
      " 'but',\n",
      " 'i',\n",
      " \"don't\",\n",
      " 'wanna',\n",
      " 'go',\n",
      " 'forth',\n",
      " 'and',\n",
      " 'back',\n",
      " 'in',\n",
      " 'constant',\n",
      " 'battles',\n",
      " '\\n',\n",
      " 'the',\n",
      " 'fact',\n",
      " 'is',\n",
      " 'i',\n",
      " 'would',\n",
      " 'rather',\n",
      " 'sit',\n",
      " 'back',\n",
      " 'and',\n",
      " 'bomb',\n",
      " 'some',\n",
      " 'rappers',\n",
      " '\\n',\n",
      " 'so',\n",
      " 'this',\n",
      " 'is',\n",
      " 'like',\n",
      " 'a',\n",
      " 'full-blown',\n",
      " 'attack',\n",
      " \"i'm\",\n",
      " \"launchin'\",\n",
      " 'at',\n",
      " \"'em\",\n",
      " '\\n',\n",
      " 'the',\n",
      " 'track',\n",
      " 'is',\n",
      " 'on',\n",
      " 'some',\n",
      " \"battlin'\",\n",
      " 'raps',\n",
      " ',',\n",
      " 'who',\n",
      " 'wants',\n",
      " 'some',\n",
      " 'static',\n",
      " '?',\n",
      " '\\n',\n",
      " \"'cause\",\n",
      " 'i',\n",
      " \"don't\",\n",
      " 'really',\n",
      " 'think',\n",
      " 'that',\n",
      " 'the',\n",
      " 'fact',\n",
      " 'that',\n",
      " \"i'm\",\n",
      " 'slim',\n",
      " 'matters',\n",
      " '\\n',\n",
      " 'a',\n",
      " 'plaque',\n",
      " 'and',\n",
      " 'platinum',\n",
      " 'status',\n",
      " 'is',\n",
      " 'wack',\n",
      " 'if',\n",
      " \"i'm\",\n",
      " 'not',\n",
      " 'the',\n",
      " 'baddest',\n",
      " ',',\n",
      " 'so',\n",
      " '\\n',\n",
      " '\\n',\n",
      " '[Chorus]',\n",
      " '\\n',\n",
      " \"'til\",\n",
      " 'the',\n",
      " 'roof',\n",
      " 'comes',\n",
      " 'off',\n",
      " ',',\n",
      " \"'til\",\n",
      " 'the',\n",
      " 'lights',\n",
      " 'go',\n",
      " 'out',\n",
      " '\\n',\n",
      " \"'til\",\n",
      " 'my',\n",
      " 'legs',\n",
      " 'give',\n",
      " 'out',\n",
      " ',',\n",
      " \"can't\",\n",
      " 'shut',\n",
      " 'my',\n",
      " 'mouth',\n",
      " '\\n',\n",
      " \"'til\",\n",
      " 'the',\n",
      " 'smoke',\n",
      " 'clears',\n",
      " 'out',\n",
      " ',',\n",
      " 'am',\n",
      " 'i',\n",
      " 'high',\n",
      " '?',\n",
      " 'perhaps',\n",
      " '\\n',\n",
      " \"i'ma\",\n",
      " 'rip',\n",
      " 'this',\n",
      " 'shit',\n",
      " \"'til\",\n",
      " 'my',\n",
      " 'bones',\n",
      " 'collapse',\n",
      " '\\n',\n",
      " \"'til\",\n",
      " 'the',\n",
      " 'roof',\n",
      " 'comes',\n",
      " 'off',\n",
      " ',',\n",
      " \"'til\",\n",
      " 'the',\n",
      " 'lights',\n",
      " 'go',\n",
      " 'out',\n",
      " '\\n',\n",
      " 'until',\n",
      " 'the',\n",
      " 'roof',\n",
      " ',',\n",
      " 'until',\n",
      " 'the',\n",
      " 'roof',\n",
      " '\\n',\n",
      " \"'til\",\n",
      " 'my',\n",
      " 'legs',\n",
      " 'give',\n",
      " 'out',\n",
      " ',',\n",
      " \"can't\",\n",
      " 'shut',\n",
      " 'my',\n",
      " 'mouth',\n",
      " '\\n',\n",
      " 'the',\n",
      " 'roof',\n",
      " 'comes',\n",
      " 'off',\n",
      " ',',\n",
      " 'the',\n",
      " 'roof',\n",
      " 'comes',\n",
      " 'off',\n",
      " '\\n',\n",
      " \"'til\",\n",
      " 'the',\n",
      " 'smoke',\n",
      " 'clears',\n",
      " 'out',\n",
      " ',',\n",
      " 'am',\n",
      " 'i',\n",
      " 'high',\n",
      " '?',\n",
      " 'perhaps',\n",
      " '\\n',\n",
      " 'until',\n",
      " 'my',\n",
      " 'legs',\n",
      " ',',\n",
      " 'until',\n",
      " 'my',\n",
      " 'legs',\n",
      " '.',\n",
      " '\\n',\n",
      " \"i'ma\",\n",
      " 'rip',\n",
      " 'this',\n",
      " 'shit',\n",
      " \"'til\",\n",
      " 'my',\n",
      " 'bones',\n",
      " 'collapse',\n",
      " '\\n',\n",
      " 'give',\n",
      " 'out',\n",
      " 'from',\n",
      " 'underneath',\n",
      " 'me',\n",
      " '\\n',\n",
      " '\\n',\n",
      " '[Outro]',\n",
      " '\\n',\n",
      " 'until',\n",
      " 'the',\n",
      " 'roof',\n",
      " ',',\n",
      " 'until',\n",
      " 'the',\n",
      " 'roof',\n",
      " '\\n',\n",
      " 'the',\n",
      " 'roof',\n",
      " 'comes',\n",
      " 'off',\n",
      " ',',\n",
      " 'the',\n",
      " 'roof',\n",
      " 'comes',\n",
      " 'off',\n",
      " '\\n',\n",
      " 'until',\n",
      " 'my',\n",
      " 'legs',\n",
      " ',',\n",
      " 'until',\n",
      " 'my',\n",
      " 'legs',\n",
      " '\\n',\n",
      " 'give',\n",
      " 'out',\n",
      " 'from',\n",
      " 'underneath',\n",
      " 'me',\n",
      " '\\n',\n",
      " 'i',\n",
      " ',',\n",
      " 'i',\n",
      " 'will',\n",
      " 'not',\n",
      " 'fall',\n",
      " ',',\n",
      " 'i',\n",
      " 'will',\n",
      " 'stand',\n",
      " 'tall',\n",
      " '\\n',\n",
      " 'feels',\n",
      " 'like',\n",
      " 'no',\n",
      " 'one',\n",
      " 'can',\n",
      " 'beat',\n",
      " 'me']\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "def print_in_chunks(lst, chunk_size=10):\n",
    "    for i in range(0, len(lst), chunk_size):\n",
    "        chunk = lst[i:i+chunk_size]\n",
    "        print(\", \".join(str(item) for item in chunk))\n",
    "\n",
    "lyric = song_lyrics['lyrics']\n",
    "text1 = lyric[0]\n",
    "tokens = tokenize_lyrics(text1)\n",
    "pprint.pprint(tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
