{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class LyricsGeneratorModel(nn.Module):\n",
    "    def __init__(self, vocab_size, num_genres, num_numeric_features):\n",
    "        super(LyricsGeneratorModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, 128)\n",
    "        self.lstm = nn.LSTM(128, 128, batch_first=True)\n",
    "        self.dense_numeric = nn.Linear(num_numeric_features, 32)\n",
    "        self.dense_genre = nn.Linear(num_genres, 32)\n",
    "        self.dense_combined = nn.Linear(128 + 32 + 32, 128)\n",
    "        self.output_layer = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, lyrics_input, numeric_input, genre_input):\n",
    "        embedded_lyrics = self.embedding(lyrics_input)\n",
    "        lstm_out, _ = self.lstm(embedded_lyrics)\n",
    "        lstm_out = lstm_out[:, -1, :]  # Get the output of the last LSTM cell\n",
    "\n",
    "        numeric_out = F.relu(self.dense_numeric(numeric_input))\n",
    "        genre_out = F.relu(self.dense_genre(genre_input))\n",
    "\n",
    "        combined = torch.cat((lstm_out, numeric_out, genre_out), dim=1)\n",
    "        combined = F.relu(self.dense_combined(combined))\n",
    "        output = self.output_layer(combined)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LyricsDataset(Dataset):\n",
    "    def __init__(self, lyrics_sequences, numeric_features, genre_features, labels):\n",
    "        self.lyrics_sequences = lyrics_sequences\n",
    "        self.numeric_features = numeric_features\n",
    "        self.genre_features = genre_features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.lyrics_sequences[idx], self.numeric_features[idx], self.genre_features[idx], self.labels[idx]\n",
    "\n",
    "# Convert your preprocessed data to PyTorch tensors and create a dataset\n",
    "train_dataset = LyricsDataset(X_train_seq, X_train_num, X_train_cat, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LyricsGeneratorModel(vocab_size, num_genres, num_numeric_features).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for lyrics, numeric, genre, labels in train_loader:\n",
    "        lyrics, numeric, genre, labels = lyrics.to(device), numeric.to(device), genre.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(lyrics, numeric, genre)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lyrics(model, seed_text, tokenizer, max_sequence_len=100, generation_length=50):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    generated_text = seed_text\n",
    "    vocab_size = len(tokenizer.word_index) + 1  # Plus one for the zero padding\n",
    "\n",
    "    for _ in range(generation_length):\n",
    "        # Tokenize and pad the current sequence\n",
    "        token_list = tokenizer.texts_to_sequences([generated_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len, padding='pre')\n",
    "        token_list = torch.tensor(token_list, dtype=torch.long).to(device)\n",
    "\n",
    "        # Predict the next word (as a token)\n",
    "        with torch.no_grad():\n",
    "            predictions = model(token_list).cpu()\n",
    "        predicted_token = torch.argmax(predictions, dim=1)[-1].item()\n",
    "\n",
    "        # Find the word corresponding to the predicted token\n",
    "        predicted_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted_token:\n",
    "                predicted_word = word\n",
    "                break\n",
    "\n",
    "        # Append the predicted word to the generated text\n",
    "        generated_text += \" \" + predicted_word\n",
    "\n",
    "    return generated_text\n",
    "\n",
    "lyrics = generate_lyrics(model, 'The sun shines', tokenizer)\n",
    "print(lyrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "features to consider:\n",
    "\n",
    "- Think about beam search\n",
    "- try many lstm layers"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
